{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpH2mpB-s19i",
        "outputId": "3427b7d4-d74c-42b6-fb5c-4a561a133456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=\"\"\"My self Md Rakibul Hasan Shaon. Currently I am learning NLP (Tokenizetin) from a femous youtuber Name Kris Nayek. i am following his gouidline\n",
        "and both theory and coding. Hope I will make it till the end and it will feel up my thrust of knowlwdge on the machine learning field.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aO_xIuuht6Vl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "id": "5U_di0rcuDQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d27718-c363-4325-bf3e-5ffa7221dc6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My self Md Rakibul Hasan Shaon. Currently I am learning NLP (Tokenizetin) from a femous youtuber Name Kris Nayek. i am following his gouidline\n",
            "and both theory and coding. Hope I will make it till the end and it will feel up my thrust of knowlwdge on the machine learning field.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentence-->paragraphs\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "Hm8JyLgkujGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6917aaa3-f14d-47f8-cb87-75689312191a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents=sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "R9X1k5aPuDMV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "id": "81l0OdWEuDJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc914d79-00a2-4900-fb49-dd2f4014180a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My self Md Rakibul Hasan Shaon.', 'Currently I am learning NLP (Tokenizetin) from a femous youtuber Name Kris Nayek.', 'i am following his gouidline\\nand both theory and coding.', 'Hope I will make it till the end and it will feel up my thrust of knowlwdge on the machine learning field.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents)"
      ],
      "metadata": {
        "id": "Uq2homo2uDHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd5a8b1-96af-444c-8727-88d31222e7dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentences in  documents:\n",
        "  print(sentences)"
      ],
      "metadata": {
        "id": "Kt_qQr1AuDEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec402c6-0341-4f44-f235-daa991f97d81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My self Md Rakibul Hasan Shaon.\n",
            "Currently I am learning NLP (Tokenizetin) from a femous youtuber Name Kris Nayek.\n",
            "i am following his gouidline\n",
            "and both theory and coding.\n",
            "Hope I will make it till the end and it will feel up my thrust of knowlwdge on the machine learning field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## sentence--->words\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "HGi1kEyGuDBl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus)"
      ],
      "metadata": {
        "id": "wO41-02OuC8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a228c0-c5cc-410c-ff24-a06bfc629f37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'self',\n",
              " 'Md',\n",
              " 'Rakibul',\n",
              " 'Hasan',\n",
              " 'Shaon',\n",
              " '.',\n",
              " 'Currently',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'NLP',\n",
              " '(',\n",
              " 'Tokenizetin',\n",
              " ')',\n",
              " 'from',\n",
              " 'a',\n",
              " 'femous',\n",
              " 'youtuber',\n",
              " 'Name',\n",
              " 'Kris',\n",
              " 'Nayek',\n",
              " '.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'following',\n",
              " 'his',\n",
              " 'gouidline',\n",
              " 'and',\n",
              " 'both',\n",
              " 'theory',\n",
              " 'and',\n",
              " 'coding',\n",
              " '.',\n",
              " 'Hope',\n",
              " 'I',\n",
              " 'will',\n",
              " 'make',\n",
              " 'it',\n",
              " 'till',\n",
              " 'the',\n",
              " 'end',\n",
              " 'and',\n",
              " 'it',\n",
              " 'will',\n",
              " 'feel',\n",
              " 'up',\n",
              " 'my',\n",
              " 'thrust',\n",
              " 'of',\n",
              " 'knowlwdge',\n",
              " 'on',\n",
              " 'the',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'field',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in documents:\n",
        "    print(word_tokenize(sentence))"
      ],
      "metadata": {
        "id": "z_t8jKWcuC51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5550a11e-dd2b-42e4-e602-d8202b842922"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My', 'self', 'Md', 'Rakibul', 'Hasan', 'Shaon', '.']\n",
            "['Currently', 'I', 'am', 'learning', 'NLP', '(', 'Tokenizetin', ')', 'from', 'a', 'femous', 'youtuber', 'Name', 'Kris', 'Nayek', '.']\n",
            "['i', 'am', 'following', 'his', 'gouidline', 'and', 'both', 'theory', 'and', 'coding', '.']\n",
            "['Hope', 'I', 'will', 'make', 'it', 'till', 'the', 'end', 'and', 'it', 'will', 'feel', 'up', 'my', 'thrust', 'of', 'knowlwdge', 'on', 'the', 'machine', 'learning', 'field', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##pharagraph to word\n",
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "GTzZB4ctuC3E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "id": "gei5iI7duC0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7784559e-3a49-4857-e995-8b71fd618817"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'self',\n",
              " 'Md',\n",
              " 'Rakibul',\n",
              " 'Hasan',\n",
              " 'Shaon',\n",
              " '.',\n",
              " 'Currently',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'NLP',\n",
              " '(',\n",
              " 'Tokenizetin',\n",
              " ')',\n",
              " 'from',\n",
              " 'a',\n",
              " 'femous',\n",
              " 'youtuber',\n",
              " 'Name',\n",
              " 'Kris',\n",
              " 'Nayek',\n",
              " '.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'following',\n",
              " 'his',\n",
              " 'gouidline',\n",
              " 'and',\n",
              " 'both',\n",
              " 'theory',\n",
              " 'and',\n",
              " 'coding',\n",
              " '.',\n",
              " 'Hope',\n",
              " 'I',\n",
              " 'will',\n",
              " 'make',\n",
              " 'it',\n",
              " 'till',\n",
              " 'the',\n",
              " 'end',\n",
              " 'and',\n",
              " 'it',\n",
              " 'will',\n",
              " 'feel',\n",
              " 'up',\n",
              " 'my',\n",
              " 'thrust',\n",
              " 'of',\n",
              " 'knowlwdge',\n",
              " 'on',\n",
              " 'the',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'field',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "k26X5PgHuCxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=TreebankWordTokenizer()\n",
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "id": "adB1SxcZuCu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b94c9123-2b0b-4da0-b1e7-49770279d25d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My',\n",
              " 'self',\n",
              " 'Md',\n",
              " 'Rakibul',\n",
              " 'Hasan',\n",
              " 'Shaon.',\n",
              " 'Currently',\n",
              " 'I',\n",
              " 'am',\n",
              " 'learning',\n",
              " 'NLP',\n",
              " '(',\n",
              " 'Tokenizetin',\n",
              " ')',\n",
              " 'from',\n",
              " 'a',\n",
              " 'femous',\n",
              " 'youtuber',\n",
              " 'Name',\n",
              " 'Kris',\n",
              " 'Nayek.',\n",
              " 'i',\n",
              " 'am',\n",
              " 'following',\n",
              " 'his',\n",
              " 'gouidline',\n",
              " 'and',\n",
              " 'both',\n",
              " 'theory',\n",
              " 'and',\n",
              " 'coding.',\n",
              " 'Hope',\n",
              " 'I',\n",
              " 'will',\n",
              " 'make',\n",
              " 'it',\n",
              " 'till',\n",
              " 'the',\n",
              " 'end',\n",
              " 'and',\n",
              " 'it',\n",
              " 'will',\n",
              " 'feel',\n",
              " 'up',\n",
              " 'my',\n",
              " 'thrust',\n",
              " 'of',\n",
              " 'knowlwdge',\n",
              " 'on',\n",
              " 'the',\n",
              " 'machine',\n",
              " 'learning',\n",
              " 'field',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_vWYvdGuCsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "faxPsbJauCqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeQQ-8YduCnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ujM0lQeuCkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjXEczeZuCh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RqwGcsf9uCfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYngyFY5uCdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ewfnb3xZuCc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LW1L45IOuCXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "feaZ9sOxuCQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ox58GUj3uCPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rr_vcGiMuCGl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}